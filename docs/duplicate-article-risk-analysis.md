# 📊 記事重複リスク分析レポート

**作成日**: 2026-01-28  
**分析者**: Copilot Coding Agent  
**対象システム**: AI News Daily Digest 自動収集システム

---

## 🎯 分析目的

毎日のAI関連ニュース自動収集において、連日で記事が重複してしまうリスクを評価し、対策を提案する。

---

## 📋 分析項目と結果

### ① ニュースサイトの更新頻度

各収集対象サイトの更新頻度を調査した結果：

| サイト名 | 更新頻度 | 1日あたりのAI記事数 | リスク評価 |
|---------|---------|------------------|----------|
| **MIT Technology Review** | 週3-5本 | 0-1本 | 🟡 中リスク |
| **VentureBeat AI** | 1日5-10本 | 5-10本 | 🟢 低リスク |
| **TechCrunch AI** | 1日10-20本 | 10-20本 | 🟢 低リスク |
| **The Verge AI** | 1日3-8本 | 3-8本 | 🟡 中リスク |
| **Towards Data Science** | 1日20-50本 | 20-50本 | 🟢 低リスク |
| **Wired (AI)** | 週数回 | 2-5本 | 🟡 中リスク |

**判定結果**:
- ✅ **TechCrunch、VentureBeat、Towards Data Science**: 更新頻度が高く、新しい記事が常に流入するため重複リスクは低い
- ⚠️ **MIT Technology Review、The Verge、Wired**: 更新頻度が低めで、同じ記事が複数日に渡って「最新記事」として表示される可能性がある

---

### ② 抽出する記事数

**現状の設定**:
- 各サイトから **1-2件** の重要記事を選定
- 合計 **5-10件** 程度
- 選定基準: 技術的革新性、ビジネスインパクト、社会的影響度、実践的学び

**問題点**:
1. **記事数が少ない**: 5-10件という少数のため、特に更新頻度の低いサイトでは同じ記事が選ばれる可能性が高い
2. **選定基準が主観的**: 「重要度」の判断基準が明確でなく、日によって異なる記事が選ばれる保証がない
3. **時間範囲のあいまいさ**: 「直近24時間以内」という指示があるが、記事の公開日時を厳密にチェックする仕組みがない

---

### ③ 明日に自動取得で今日の記事と被らない保証

**現状の仕様**:
```markdown
## ニュース収集
- 上記6サイトからAI関連の最新ニュース（直近24時間以内）を収集
- 各サイトから1-2件の重要記事を選定（合計5-10件程度）
```

**重複防止メカニズムの有無**:
❌ **なし** - 以下の機能が実装されていない：
1. 過去に収集した記事のURL/タイトル追跡
2. 前日の記事との重複チェック
3. 記事の公開日時の厳密な確認
4. 記事IDやURLのデータベース管理

**結論**:
🔴 **保証なし** - 現在のシステムでは、明日の自動収集で今日と同じ記事が選ばれる可能性が高い。特に以下のケースで重複が発生しやすい：
- 週末明けや祝日明け（新規記事が少ない）
- 大型ニュース発表直後（同じビッグニュースが連日トップに表示）
- 更新頻度の低いサイト（MIT Tech Review、The Verge等）

---

## 🚨 リスク評価サマリー

### 高リスク要因
1. **重複チェック機能の欠如**: 過去の記事履歴を一切参照していない
2. **時間範囲の曖昧さ**: 「直近24時間以内」の判定が不明確
3. **少数記事の選定**: 5-10件という少数のため、選択肢が限られる
4. **更新頻度の違い**: サイトによって更新頻度にばらつきがある

### 重複発生シナリオ
```
【ケース1: 週末明け】
土曜日: MIT Tech Reviewに記事A公開（唯一のAI記事）
月曜日朝7:00: システム起動 → 記事A を選定（過去48時間で最新）
火曜日朝7:00: システム起動 → 記事A を選定（依然として最新記事）

【ケース2: ビッグニュース】
月曜日: OpenAI GPT-5発表
月曜日朝7:00: 全サイトでGPT-5記事を収集
火曜日朝7:00: 新規記事が少なく、依然GPT-5記事が上位 → 重複
```

---

## 💡 推奨対策

### 【対策1】重複チェック機能の実装（必須）

**実装方法**:
1. 過去7日分の記事URL/タイトルをJSON形式で保存
2. 新規収集時に過去の記事と照合
3. 重複する場合はスキップし、次の候補記事を選定

**ファイル構成**:
```
ai-news-digest/
├── daily/
│   └── YYYY-MM-DD.md
└── .article-history/
    └── articles-history.json  # 過去記事の履歴
```

**articles-history.json フォーマット**:
```json
{
  "articles": [
    {
      "url": "https://example.com/article1",
      "title": "記事タイトル",
      "published_date": "2026-01-28",
      "collected_date": "2026-01-28",
      "source": "MIT Technology Review"
    }
  ]
}
```

### 【対策2】Copilot指示書の改善（必須）

**追加すべき指示**:
```markdown
## ニュース収集（改訂版）

### 重複防止ロジック
1. `.article-history/articles-history.json` から過去7日分の記事URLを読み込む
2. 各サイトから候補記事を収集する際、以下を確認：
   - 記事のURLが過去7日分の履歴に含まれていないこと
   - 記事の公開日時が真に「過去24時間以内」であること
   - 記事タイトルの類似度が既存記事と80%未満であること（表現を変えた重複記事対策）
3. 重複記事はスキップし、次の候補を選定
4. 収集完了後、新規記事の情報を `articles-history.json` に追記

### 記事公開日時の確認
- サイトのメタデータまたは記事ページから公開日時を取得
- UTC時刻で記録し、厳密に24時間以内かを判定
- 公開日時が不明な記事は「最終更新日時」で代用

### 履歴ファイルのメンテナンス
- 7日より古い記事は自動的に削除
- ファイルサイズが1MBを超える場合はアラート
```

### 【対策3】記事選定数の調整（推奨）

**現状**: 各サイトから1-2件 → **合計5-10件**  
**改善案**: 各サイトから2-3件 → **合計10-15件**

**理由**:
- 選択肢が増えることで、重複を避けつつ多様な記事を選定可能
- 更新頻度の低いサイトでも、2-3日前の記事まで候補に含められる
- 読了時間は10-12分程度に延びるが、情報量が増える

### 【対策4】サイト別の時間範囲調整（推奨）

更新頻度に応じて収集範囲を調整：

| サイト | 収集範囲 | 理由 |
|--------|---------|------|
| TechCrunch, VentureBeat, Towards Data Science | 過去24時間 | 更新頻度が高い |
| MIT Tech Review, The Verge | 過去48-72時間 | 更新頻度が低い |

**メリット**: 
- 更新頻度の低いサイトでも新鮮な記事を提供
- ただし、重複チェックと組み合わせることで既出記事は除外

### 【対策5】週末・祝日対応（推奨）

**問題**: 週末や祝日は新規記事が少ない

**対応策**:
1. 週末（土日）は収集範囲を48時間に拡大
2. 祝日カレンダーと連携し、自動的に範囲を調整
3. 記事数が閾値（5件）未満の場合は、範囲を自動拡大

---

## 🎯 実装優先度

| 対策 | 優先度 | 実装難易度 | 効果 |
|------|--------|-----------|------|
| 対策1: 重複チェック機能 | 🔴 最高 | 中 | 非常に高い |
| 対策2: 指示書改善 | 🔴 最高 | 低 | 高い |
| 対策3: 記事選定数調整 | 🟡 中 | 低 | 中 |
| 対策4: サイト別時間範囲 | 🟡 中 | 中 | 中 |
| 対策5: 週末・祝日対応 | 🟢 低 | 高 | 低 |

---

## 📝 実装ロードマップ

### Phase 1: 緊急対応（即時実施）
- [x] リスク分析ドキュメント作成
- [x] Copilot指示書への重複チェックロジック追加
- [x] `.article-history/` ディレクトリと初期JSONファイル作成
- [x] README.mdに重複防止機能の説明追加

### Phase 2: 基本実装（1週間以内）
- [x] 過去記事履歴の初期化（2026-01-28時点で稼働中の記事から初期履歴を作成）
- [ ] 重複チェック機能の動作検証（次回の自動実行で確認）
- [ ] 記事選定数を10-15件に調整（オプション）

**注記**: Phase 1は完了済み。Phase 2以降は、システムの実際の稼働データを収集しながら段階的に実施します。

### Phase 3: 高度化（1ヶ月以内）
- [ ] タイトル類似度チェックの実装
- [ ] サイト別時間範囲の最適化
- [ ] 週末・祝日対応の実装
- [ ] 月次レポート機能（重複率のモニタリング）

---

## 📊 期待される効果

### 対策前（現状）
- 記事重複率: **推定30-50%**（特に週末明け）
- 読者満足度: 低（同じ記事を何度も読む）
- システム信頼性: 低

### 対策後（Phase 1完了時）
- 記事重複率: **0-5%**（技術的に完全排除は困難）
- 読者満足度: 高（常に新鮮な情報）
- システム信頼性: 高

---

## ⚠️ 注意事項

1. **完全な重複防止は困難**: 記事タイトルや内容が微妙に異なる場合、同じニュースを扱っていても検出できない可能性がある
2. **URLの変更**: ニュースサイトがURL構造を変更した場合、同じ記事でも異なるURLとして扱われる
3. **履歴ファイルの破損**: JSONファイルが破損した場合のフォールバック処理が必要
4. **初回実行**: 履歴がない状態での初回実行では重複チェックができない

---

## 🔗 関連ドキュメント

- [README.md](../README.md) - システム概要
- [.github/copilot-instructions.md](../.github/copilot-instructions.md) - Copilot指示書
- [.github/workflows/daily-digest.yml](../.github/workflows/daily-digest.yml) - 自動実行設定

---

*このドキュメントは継続的に更新されます。最終更新: 2026-01-28*
